{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from models.Ensemble import LogisticRegressionModel\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "if os.getcwd()[-15:] != 'BachelorProject':\n",
    "    os.chdir('../')\n",
    "\n",
    "from utils.metrics import get_link_prediction_metrics\n",
    "from tgb.linkproppred.evaluate import Evaluator\n",
    "\n",
    "\n",
    "# Import data\n",
    "folder_name = 'DTU_Test/Test_folder'\n",
    "logits = {}\n",
    "labels = {}\n",
    "MRRs = {}\n",
    "\n",
    "for model_folder in os.listdir(folder_name):\n",
    "    if '_' in model_folder:\n",
    "        continue\n",
    "\n",
    "    model_folder_path = f'{folder_name}/{model_folder}'\n",
    "    for data_name in os.listdir(model_folder_path):\n",
    "        if data_name != 'tgbl-flight':\n",
    "            continue\n",
    "        for run_name in os.listdir(f'{model_folder_path}/{data_name}'):\n",
    "            if '.' in run_name:\n",
    "                continue\n",
    "            for file_name in os.listdir(f'{model_folder_path}/{data_name}/{run_name}'):\n",
    "                #print(file_name)\n",
    "                # OBS exception for EdgeBank!\n",
    "\n",
    "                if 'logits' in file_name:\n",
    "                    data = torch.load(f'{model_folder_path}/{data_name}/{run_name}/{file_name}', map_location=torch.device('cpu'))\n",
    "                    if type(data[0]) == torch.Tensor:\n",
    "                        logits[file_name] = data if 'EdgeBank' not in file_name else torch.stack(data).flatten()\n",
    "                    else:\n",
    "                        logits[file_name] = data if 'EdgeBank' not in file_name else torch.Tensor(np.array(data).flatten())\n",
    "                elif 'labels' in file_name:\n",
    "                    data = torch.load(f'{model_folder_path}/{data_name}/{run_name}/{file_name}', map_location=torch.device('cpu'))\n",
    "                    if type(data[0]) == torch.Tensor:\n",
    "                        labels[file_name] = data if 'EdgeBank' not in file_name else torch.stack(data).flatten()\n",
    "                    else:\n",
    "                        labels[file_name] = data if 'EdgeBank' not in file_name else torch.Tensor(np.array(data).flatten())\n",
    "                elif 'all_val_metric' in file_name:\n",
    "                    MRRs[model_folder] = np.load(f'{model_folder_path}/{data_name}/{run_name}/{file_name}')\n",
    "\n",
    "# Find best epoch for each model\n",
    "model_names = ['EdgeBank'] + list(MRRs.keys())\n",
    "best_epochs = {}\n",
    "for model in MRRs:\n",
    "    best_epochs[model] = MRRs[model].argmax()\n",
    "\n",
    "# Training + test data (train: logits from best epoch)\n",
    "training_data = {}\n",
    "test_data = {}\n",
    "\n",
    "for key in logits:\n",
    "    model_name = key.split('_')[0]\n",
    "    if 'train' in key:\n",
    "        training_data[model_name] = logits[key] if model_name=='EdgeBank' else logits[key][best_epochs[model_name]].detach().numpy()\n",
    "    elif 'test' in key:\n",
    "        test_data[model_name] = logits[key] if model_name=='EdgeBank' else logits[key].detach().numpy()\n",
    "\n",
    "# Add labels\n",
    "for key in labels:\n",
    "    if not 'labels' in training_data.keys() and 'train' in key:\n",
    "        training_data['labels'] = labels[key][0]\n",
    "    elif not 'labels' in test_data.keys() and 'test' in key:\n",
    "        test_data['labels'] = labels[key]\n",
    "\n",
    "train_df = pd.DataFrame(training_data)\n",
    "test_df = pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in training_data:\n",
    "#     print(key, training_data[key].shape)\n",
    "#     print(key, test_data[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are labels the same? YES\n",
    "# for key1 in labels.keys():\n",
    "#     for key2 in labels.keys():\n",
    "#         if key1 == key2 or key1.split('_')[-1] != key2.split('_')[-1]:\n",
    "#             continue\n",
    "\n",
    "#         if not np.array_equal(labels[key1][np.random.randint(len(labels[key1]))], labels[key2][np.random.randint(len(labels[key2]))]):\n",
    "#             print(f'Labels {key1} and {key2} are not equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Class imbalance\n",
    "# for file in ['TGN_tgbl-wiki_labels_train.pth', 'TGN_tgbl-wiki_labels_test.pth']:\n",
    "#     data = labels[file] if not 'train' in file else labels[file].T\n",
    "#     print(data.shape)\n",
    "\n",
    "#     print(sum(data == 1))\n",
    "#     print(sum(data == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "random.seed(2024)\n",
    "\n",
    "if os.getcwd()[-15:] != 'BachelorProject':\n",
    "    os.chdir('../')\n",
    "\n",
    "from utils.metrics import get_link_prediction_metrics\n",
    "from tgb.linkproppred.evaluate import Evaluator\n",
    "\n",
    "model_performances = {}\n",
    "\n",
    "for model_name in model_names:\n",
    "    if model_name == 'EdgeBank':\n",
    "        continue\n",
    "    combiner = LogisticRegressionModel(input_dim=2, output_dim=1, manual_init=False)\n",
    "    loss_func = nn.BCEWithLogitsLoss()\n",
    "    evaluator = Evaluator(name='tgbl-wiki')\n",
    "    \n",
    "    optimizer = torch.optim.Adam(combiner.parameters(), lr=0.01, weight_decay=0.0)\n",
    "    models = [model_name, 'EdgeBank']\n",
    "    labels = train_df['labels'].values\n",
    "    combined_logits = train_df[models].values\n",
    "\n",
    "    logit_batches = np.array_split(combined_logits, len(combined_logits)/2000)\n",
    "    labels_batches = np.array_split(labels, len(labels)/2000)\n",
    "    weights = [combiner.get_weights()[1]]\n",
    "    losses = []\n",
    "    combiner.train()\n",
    "\n",
    "    for epoch in range(1):\n",
    "        for batch, labels in zip(logit_batches, labels_batches):\n",
    "            batch = torch.Tensor(batch)\n",
    "            labels = torch.Tensor(labels)\n",
    "            output = combiner.forward(batch, return_logits=True).squeeze(1)\n",
    "            loss = loss_func(output, labels)\n",
    "            losses.append(loss.item())\n",
    "            optimizer.zero_grad()\n",
    "            weights.append(combiner.get_weights()[1])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    test_combined_logits = test_df[models].values\n",
    "    test_batches = np.array_split(test_combined_logits, len(test_combined_logits)/101)\n",
    "    test_label_batches = np.array_split(test_df['labels'].values, len(test_df)/101)\n",
    "\n",
    "    mrrs = []\n",
    "    pr_aucs = []\n",
    "    roc_aucs = []\n",
    "\n",
    "    combiner.eval()\n",
    "\n",
    "    for batch, test_label_batches in zip(test_batches, test_label_batches):\n",
    "        batch = torch.Tensor(batch)\n",
    "        predicts = combiner.forward(batch, return_logits=False).squeeze(1)\n",
    "        mrrs.append(evaluator.eval({'y_pred_pos': predicts[0], 'y_pred_neg': predicts[1:], 'eval_metric': ['mrr']})['mrr'])\n",
    "        train_perf = get_link_prediction_metrics(predicts, torch.Tensor(test_label_batches))\n",
    "        pr_aucs.append(train_perf['pr_auc'])\n",
    "        roc_aucs.append(train_perf['roc_auc'])\n",
    "\n",
    "\n",
    "    mrr = np.mean(np.array(mrrs))\n",
    "    pr_auc = np.mean(np.array(pr_aucs))\n",
    "    roc_auc = np.mean(np.array(roc_aucs))\n",
    "\n",
    "    print('model:', models)\n",
    "    print('mrr:', mrr)\n",
    "    print('pr-auc:', pr_auc)\n",
    "    print('roc-auc:', roc_auc)\n",
    "\n",
    "    mean_losses = []\n",
    "    for i in range(0, len(losses), len(logit_batches)):\n",
    "        mean_losses.append(np.mean(losses[i:i+len(logit_batches)]))\n",
    "\n",
    "    # print('mean loss:', mean_losses)\n",
    "\n",
    "    xticks = np.arange(0, len(losses), len(logit_batches))\n",
    "\n",
    "    # Subplots of weights and losses\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Plot for losses\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(np.array(losses), label='Losses') \n",
    "    plt.plot(xticks, np.array(mean_losses))  \n",
    "    plt.xlabel('Batches')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss for ensemble of ' + model_name + ' and EdgeBank')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot for weights\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(np.array(weights), label='Weights')\n",
    "    plt.legend(combiner.get_weights()[0])\n",
    "    plt.xlabel('Batches')\n",
    "    plt.ylabel('Weights')\n",
    "    plt.title('Weights for ensemble of ' + model_name + ' and EdgeBank')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # model_performances['EdgeBank_' + model_name] = [mrr, pr_auc, roc_auc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add row names to the dataframe\n",
    "pd.DataFrame(model_performances, index=['MRR', 'PR-AUC', 'ROC-AUC'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tgb_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
